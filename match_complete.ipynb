{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oracledb\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "un = 'interpro'\n",
    "cs = 'ora-dlvm-119.ebi.ac.uk:1521/IPREAD'\n",
    "pw = \"olymp\"\n",
    "\n",
    "db = oracledb.connect(user=un, password=pw, dsn=cs)\n",
    "cursor = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"WITH limited_protein AS (\n",
    "    -- Limit the number of rows from the PROTEIN table\n",
    "    SELECT PROTEIN_AC, NAME, DBCODE, CRC64, LEN,\n",
    "           TO_CHAR(TIMESTAMP, 'YYYY-MM-DD') AS TIMESTAMP,\n",
    "           FRAGMENT, TO_CHAR(TAX_ID) AS TAX_ID\n",
    "    FROM INTERPRO.PROTEIN\n",
    "    WHERE PROTEIN_AC = 'A0A009GKR3' -- Adjust this limit as needed\n",
    "    ORDER BY PROTEIN_AC\n",
    "),\n",
    "limited_matches AS (\n",
    "    -- Limit the number of rows from the MATCH and FEATURE_MATCH tables\n",
    "    SELECT PROTEIN_AC, METHOD_AC, MODEL_AC, POS_FROM, POS_TO, FRAGMENTS, SCORE\n",
    "    FROM INTERPRO.MATCH\n",
    ")\n",
    "SELECT P.PROTEIN_AC, P.NAME, P.DBCODE, P.CRC64, P.LEN, P.TIMESTAMP, P.FRAGMENT, P.TAX_ID,\n",
    "       M.METHOD_AC, M.MODEL_AC, M.POS_FROM, M.POS_TO, M.FRAGMENTS, M.SCORE, MN.NAME\n",
    "FROM limited_protein P\n",
    "INNER JOIN limited_matches M\n",
    "ON P.PROTEIN_AC = M.PROTEIN_AC\n",
    "INNER JOIN INTERPRO.METHOD MN\n",
    "ON M.METHOD_AC = MN.METHOD_AC\n",
    "ORDER BY P.PROTEIN_AC\n",
    "\"\"\"\n",
    "\n",
    "protein_data = cursor.execute(sql)\n",
    "protein_data = [\n",
    "    [str(value) if value is not None else '' for value in row]\n",
    "    for row in protein_data\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xml(protein_data):\n",
    "\n",
    "    # Convert the protein_data list into a pandas DataFrame\n",
    "    df = pd.DataFrame(protein_data, columns=[\n",
    "        'protein_id', 'name', 'dbcode', 'crc64', 'length', 'timestamp', 'fragment', 'tax_id',\n",
    "        'method_ac', 'model_ac', 'pos_from', 'pos_to', 'fragments', 'score', 'method_mn'\n",
    "    ])\n",
    "    \n",
    "    # Group by protein_id and method_ac, then create a nested dictionary\n",
    "    grouped = {}\n",
    "\n",
    "    # Iterate over each row and populate the nested dictionary\n",
    "    for _, row in df.iterrows():\n",
    "        protein_id = row['protein_id']\n",
    "        match_id = row['method_ac']\n",
    "        location = {\n",
    "            'start': row['pos_from'],\n",
    "            'end': row['pos_to'],\n",
    "            'fragments': row['fragments'],\n",
    "            'score': row['score']\n",
    "        }\n",
    "\n",
    "        if (not(protein_id in grouped.keys())):\n",
    "            grouped[protein_id] = {\n",
    "                \"info\": {\n",
    "                \"id\": row[\"protein_id\"],\n",
    "                \"name\": row[\"name\"],\n",
    "                \"length\": row[\"length\"],\n",
    "                \"crc64\": row[\"crc64\"],\n",
    "                }\n",
    "            }\n",
    "        \n",
    "\n",
    "        # Add the match_id and its location under the protein_id\n",
    "        if (not(match_id in grouped[protein_id].keys())):\n",
    "            grouped[protein_id][match_id] = {\n",
    "                \"id\": match_id,\n",
    "                \"name\": row[\"method_mn\"],\n",
    "                \"dbcode\": row[\"dbcode\"],\n",
    "                \"model\": row[\"model_ac\"],\n",
    "                \"locations\": [location]\n",
    "            }\n",
    "        else:\n",
    "            grouped[protein_id][match_id][\"locations\"].append(location)\n",
    "\n",
    "    # Create the root element for XML\n",
    "    root = ET.Element(\"proteins\")\n",
    "\n",
    "    # Iterate through the grouped data to create XML structure\n",
    "    for protein_id, protein_data in grouped.items():\n",
    "        # Extract the info for the protein\n",
    "        info = protein_data[\"info\"]\n",
    "        \n",
    "        # Create a protein element\n",
    "        protein_elem = ET.SubElement(root, \"protein\", \n",
    "                                     id=info[\"id\"], \n",
    "                                     name=info[\"name\"], \n",
    "                                     length=str(info[\"length\"]), \n",
    "                                     crc64=info[\"crc64\"])\n",
    "        \n",
    "        # Iterate over matches under this protein\n",
    "        for match_id, match_data in protein_data.items():\n",
    "            if match_id == \"info\":\n",
    "                continue  # Skip the info entry\n",
    "\n",
    "            # Create a match element under the protein\n",
    "            match_elem = ET.SubElement(protein_elem, \"match\", \n",
    "                                       id=match_data[\"id\"], \n",
    "                                       name=match_data[\"name\"], \n",
    "                                       dbname=match_data[\"dbcode\"], \n",
    "                                       model=match_data[\"model\"])\n",
    "\n",
    "            # Create lcn elements for each location in the match\n",
    "            for loc in match_data[\"locations\"]:\n",
    "                lcn_elem = ET.SubElement(match_elem, \"lcn\", \n",
    "                                         start=str(loc['start']), \n",
    "                                         end=str(loc['end']),\n",
    "                                         fragments=str(loc['fragments']),\n",
    "                                         score=str(loc['score']))\n",
    "\n",
    "    # Create an XML tree and write it to a file\n",
    "    tree = ET.ElementTree(root)\n",
    "    tree.write(\"output.xml\", encoding=\"utf-8\", xml_declaration=True)\n",
    "\n",
    "    print(grouped)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A0A009GKR3': {'info': {'id': 'A0A009GKR3', 'name': 'A0A009GKR3_9GAMM', 'length': '289', 'crc64': '6EE55E7A2BDC8AD1'}, 'G3DSA:2.60.40.10': {'id': 'G3DSA:2.60.40.10', 'name': '', 'dbcode': 'T', 'model': '5irbA02', 'locations': [{'start': '56', 'end': '155', 'fragments': '56-155-S', 'score': '4.8e-06'}, {'start': '161', 'end': '260', 'fragments': '161-260-S', 'score': '2.9e-06'}]}, 'PS00018': {'id': 'PS00018', 'name': 'EF_HAND_1', 'dbcode': 'T', 'model': 'PS00018', 'locations': [{'start': '273', 'end': '285', 'fragments': '273-285-S', 'score': '0.0'}]}}}\n"
     ]
    }
   ],
   "source": [
    "xml_data = create_xml(protein_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "match_complete",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
