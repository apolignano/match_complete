{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import oracledb\n",
    "import xml.etree.ElementTree as ET\n",
    "import xmltodict\n",
    "from deepdiff import DeepDiff\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xml(protein_data):\n",
    "\n",
    "    # Convert the protein_data list into a pandas DataFrame\n",
    "    df = pd.DataFrame(protein_data, columns=[\n",
    "        'protein_id', 'name', 'dbcode', 'crc64', 'length', 'timestamp', 'fragment', 'tax_id',\n",
    "        'method_ac', 'model_ac', 'pos_from', 'pos_to', 'fragments', 'score', 'method_desc', 'status', 'dbname', 'evd'\n",
    "    ])\n",
    "    \n",
    "    # Group by protein_id and method_ac, then create a nested dictionary\n",
    "    grouped = {}\n",
    "\n",
    "    # Iterate over each row and populate the nested dictionary\n",
    "    for _, row in df.iterrows():\n",
    "\n",
    "        protein_id = row['protein_id']\n",
    "\n",
    "        if (not(protein_id in grouped.keys())):\n",
    "            grouped[protein_id] = {\n",
    "                \"info\": {\n",
    "                \"id\": row[\"protein_id\"],\n",
    "                \"name\": row[\"name\"],\n",
    "                \"length\": row[\"length\"],\n",
    "                \"crc64\": row[\"crc64\"],\n",
    "                }\n",
    "        }\n",
    "            \n",
    "    \n",
    "        match_id = row['method_ac']\n",
    "        location = {\n",
    "            'start': row['pos_from'],\n",
    "            'end': row['pos_to'],\n",
    "            'fragments': row['fragments'],\n",
    "            'score': int(float(row[\"score\"])) if row[\"score\"][-2:] == \".0\" else row[\"score\"]\n",
    "        }\n",
    "\n",
    "        print(location)\n",
    "\n",
    "        if (match_id != \"\"):\n",
    "            # Add the match_id and its location under the protein_id\n",
    "            if (not(match_id in grouped[protein_id].keys())):\n",
    "                grouped[protein_id][match_id] = {\n",
    "                    \"id\": match_id,\n",
    "                    \"name\": row[\"method_desc\"],\n",
    "                    \"dbname\": row[\"dbname\"],\n",
    "                    \"status\": row[\"status\"],\n",
    "                    \"model\": row[\"model_ac\"],\n",
    "                    \"evd\": row[\"evd\"], \n",
    "                    \"locations\": [location]\n",
    "                }\n",
    "            else:\n",
    "                grouped[protein_id][match_id][\"locations\"].append(location)\n",
    "\n",
    "    \n",
    "\n",
    "    # Create the root element for XML\n",
    "    root = ET.Element(\"proteins\")\n",
    "\n",
    "    # Iterate through the grouped data to create XML structure\n",
    "    for protein_id, protein_data in grouped.items():\n",
    "        # Extract the info for the protein\n",
    "        info = protein_data[\"info\"]\n",
    "        \n",
    "        # Create a protein element\n",
    "        protein_elem = ET.SubElement(root, \"protein\", \n",
    "                                     id=info[\"id\"], \n",
    "                                     name=info[\"name\"], \n",
    "                                     length=str(info[\"length\"]), \n",
    "                                     crc64=info[\"crc64\"])\n",
    "        \n",
    "        # Iterate over matches under this protein\n",
    "        for match_id, match_data in protein_data.items():\n",
    "            if match_id == \"info\":\n",
    "                continue  # Skip the info entry\n",
    "            \n",
    "            # Create a match element under the protein\n",
    "            match_elem = ET.SubElement(protein_elem, \"match\", \n",
    "                                       id=match_data[\"id\"], \n",
    "                                       name=match_data[\"name\"], \n",
    "                                       dbname=match_data[\"dbname\"],\n",
    "                                       status=match_data[\"status\"], \n",
    "                                       model=match_data[\"model\"],\n",
    "                                       evd=match_data[\"evd\"])\n",
    "            \n",
    "\n",
    "            # Create lcn elements for each location in the match\n",
    "            for loc in match_data[\"locations\"]:\n",
    "                \n",
    "                frag_str = \"\"\n",
    "\n",
    "                if (loc[\"fragments\"]):\n",
    "                    frag_list = sorted(loc['fragments'].split(\",\"), key=lambda x: (x.split(\"-\")[2]))\n",
    "                    frag_list = sorted(loc['fragments'].split(\",\"), key=lambda x: (int(x.split(\"-\")[0])))\n",
    "                    frag_str = ','.join(frag_list)\n",
    "                else:\n",
    "                     frag_str = '-'.join([loc[\"start\"], loc[\"end\"], \"S\"])\n",
    "\n",
    "                lcn_elem = ET.SubElement(match_elem, \"lcn\", \n",
    "                                         start=str(loc['start']), \n",
    "                                         end=str(loc['end']),\n",
    "                                         fragments=frag_str,\n",
    "                                         score=str(loc['score']))\n",
    "    \n",
    "    # Create an XML tree and write it to a file\n",
    "    tree = ET.ElementTree(root)\n",
    "    tree.write(\"output.xml\", encoding=\"utf-8\", xml_declaration=True)\n",
    "\n",
    "    return grouped\n",
    "\n",
    "def standardize():\n",
    "\n",
    "    # Load the XML file\n",
    "    tree = ET.parse(\"output.xml\")\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Iterate over each protein and sort its matches\n",
    "    for protein in root.findall('protein'):\n",
    "        # Get all match elements\n",
    "        matches = list(protein.findall('match'))\n",
    "\n",
    "        # Sort matches by the 'score' attribute (convert score to integer for sorting)\n",
    "        sorted_matches = sorted(matches, key=lambda x: x.get('id'))\n",
    "\n",
    "        # Clear the original match elements from the protein\n",
    "        for match in matches:\n",
    "            protein.remove(match)\n",
    "\n",
    "        # Append the sorted match elements back to the protein\n",
    "        for match in sorted_matches:\n",
    "            protein.append(match)\n",
    "\n",
    "            locations = list(match.findall('lcn'))\n",
    "            sorted_lcsn = sorted(locations, key=lambda x: int(x.get('start')))\n",
    "\n",
    "                # Clear the original match elements from the protein\n",
    "            for lcn in locations:\n",
    "                match.remove(lcn)\n",
    "\n",
    "        # Append the sorted match elements back to the protein\n",
    "            for lcn in sorted_lcsn:\n",
    "                match.append(lcn)\n",
    "\n",
    "    # Save the modified XML back to a file\n",
    "    tree.write(\"output.xml\", encoding='utf-8', xml_declaration=True)\n",
    "\n",
    "def get_differences(new_path, original_path):\n",
    "    new = xmltodict.parse(open(new_path, \"r\").read(), attr_prefix = \"\", process_namespaces=True)\n",
    "    original = xmltodict.parse(open(original_path, \"r\").read(), attr_prefix = \"\", process_namespaces=True)\n",
    "    return new, original, DeepDiff(new, original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "un = 'interpro'\n",
    "cs = 'ora-dlvm-119.ebi.ac.uk:1521/IPREAD'\n",
    "pw = \"olymp\"\n",
    "\n",
    "db = oracledb.connect(user=un, password=pw, dsn=cs)\n",
    "cursor = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the XML file\n",
    "tree = ET.parse(\"original.xml\")\n",
    "root = tree.getroot()\n",
    "\n",
    "# Find all <lcn> elements and remove the 'representative' attribute if present\n",
    "for lcn in root.findall('.//lcn'):\n",
    "    if 'representative' in lcn.attrib:\n",
    "        del lcn.attrib['representative']\n",
    "\n",
    "# Find all <ipr> elements and remove them\n",
    "# Iterate over a copy of the list of <ipr> elements to avoid modifying the list while iterating\n",
    "for ipr in root.findall('.//ipr'):\n",
    "    # Get the parent of <ipr> by iterating over the tree\n",
    "    for parent in root.iter():\n",
    "        if ipr in parent:\n",
    "            parent.remove(ipr)\n",
    "            break  # Exit the loop once the <ipr> element is removed\n",
    "        \n",
    "# Write the modified tree back to the XML file (or a new file)\n",
    "tree.write(\"processed.xml\", encoding=\"utf-8\", xml_declaration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(\"processed.xml\") \n",
    "root = tree.getroot()\n",
    "\n",
    "# Extract protein IDs\n",
    "protein_ids = [protein.get(\"id\") for protein in root.findall('protein')]\n",
    "proteins_sql = [\"\\'\" + protein  + \"\\'\" for protein in protein_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = f\"\"\"\n",
    "\n",
    "WITH \n",
    "\n",
    "proteins AS (\n",
    "    SELECT PROTEIN_AC, NAME, DBCODE, CRC64, LEN,\n",
    "           TO_CHAR(TIMESTAMP, 'YYYY-MM-DD') AS TIMESTAMP,\n",
    "           FRAGMENT, TO_CHAR(TAX_ID) AS TAX_ID\n",
    "    FROM INTERPRO.PROTEIN\n",
    "    WHERE PROTEIN_AC IN ({','.join(proteins_sql)})\n",
    "    ORDER BY PROTEIN_AC\n",
    "),\n",
    "\n",
    "matches AS (\n",
    "    -- Limit the number of rows from the MATCH and FEATURE_MATCH tables\n",
    "    SELECT PROTEIN_AC, METHOD_AC, MODEL_AC, POS_FROM, POS_TO, FRAGMENTS, SCORE, DBCODE, EVIDENCE, STATUS\n",
    "    FROM INTERPRO.MATCH\n",
    ")\n",
    "\n",
    "SELECT P.PROTEIN_AC, P.NAME, M.DBCODE, P.CRC64, P.LEN, P.TIMESTAMP, P.FRAGMENT, P.TAX_ID,\n",
    "       M.METHOD_AC, M.MODEL_AC, M.POS_FROM, M.POS_TO, M.FRAGMENTS, M.SCORE, MN.DESCRIPTION, M.STATUS,\n",
    "       DB.DBSHORT, CE.ABBREV\n",
    "\n",
    "FROM proteins P\n",
    "LEFT OUTER JOIN matches M\n",
    "ON P.PROTEIN_AC = M.PROTEIN_AC\n",
    "\n",
    "LEFT OUTER JOIN INTERPRO.METHOD MN\n",
    "ON M.METHOD_AC = MN.METHOD_AC\n",
    "\n",
    "LEFT OUTER JOIN INTERPRO.CV_DATABASE DB\n",
    "ON M.DBCODE = DB.DBCODE\n",
    "\n",
    "LEFT OUTER JOIN CV_EVIDENCE CE\n",
    "ON M.EVIDENCE = CE.CODE\n",
    "\n",
    "ORDER BY P.PROTEIN_AC\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_data = cursor.execute(sql)\n",
    "protein_data = [[str(value) if value is not None else '' for value in row] for row in protein_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_data = create_xml(protein_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, o, d = get_differences(\"processed.xml\", \"output.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"differences.json\", \"w\").write(json.dumps(d))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "match_complete",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
